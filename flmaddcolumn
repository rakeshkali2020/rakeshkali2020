try:
    if week=="0" or day =="1":
            
        [tableQuery] = query[deltaTableName].replace("\n"," ").replace("\t"," ").split('|')
        spark.sql(tableQuery)

        [tableInsertQuery] = insert[deltaTableName].replace("\n"," ").replace("\t"," ").split('|')
        spark.sql(tableInsertQuery)


    else:

        # --------------------------modified records in current file ----------------------------
        df_update=spark.sql("""
with cte_5 (select distinct global_item_number,dc,salesorg,customer_number,date,sha2(concat(demand_plan_quantity,primary_stat_forecast_quantity,seasonality_quantity,customer_level_promotions_quantity,manual_promotions_quantity,manual_dp_adjustment_quantity,proposed_demand_plan_quantity,sop_approved_forecast_quantity,sales_planning_tool_promotions_quantity,business_decision_quantity,constraints_quantity,media_quantity,pricing_quantity,cannibalization_quantity,consumption_quantity,distribution_quantity,placeholders_quantity,approved_promo_override,fc1_quantity,fc2_quantity,fc3_quantity,pl_quantity,total_sales_plan_quantity,total_promo_quantity,promobaseline_quantity, total_spt_quantity,extrenaldemand_quantity,distributorprimary_quantity,CONSENSUS_DEMAND_PLAN_QUANTITY,CONSTRAINED_DEMAND_PLAN_QUANTITY,FD_REGRESSOR_QUANTITY),256)as hashkey from """+raw+""" where to_date(timestamp)='"""+today+"""' ),
 cte_4 (select distinct global_item_number,dc,salesorg,customer_number,date,sha2(concat(demand_plan_quantity,primary_stat_forecast_quantity,seasonality_quantity,customer_level_promotions_quantity,manual_promotions_quantity,manual_dp_adjustment_quantity,
proposed_demand_plan_quantity,sop_approved_forecast_quantity,sales_planning_tool_promotions_quantity,business_decision_quantity,constraints_quantity,media_quantity,pricing_quantity,cannibalization_quantity,consumption_quantity,distribution_quantity,placeholders_quantity,approved_promo_override,fc1_quantity,fc2_quantity,fc3_quantity,pl_quantity,total_sales_plan_quantity,total_promo_quantity,promobaseline_quantity, total_spt_quantity,extrenaldemand_quantity,distributorprimary_quantity,CONSENSUS_DEMAND_PLAN_QUANTITY,CONSTRAINED_DEMAND_PLAN_QUANTITY,FD_REGRESSOR_QUANTITY),256)as hashkey from """+stg+""" where to_date(timestamp)='"""+min_date+"""'  and salesorg in (select distinct salesorg from """+raw+""") )
select  distinct global_item_number,dc,salesorg,customer_number from (select a.global_item_number,a.dc,a.salesorg,a.customer_number,a.date,a.hashkey,b.hashkey, case when a.hashkey = b.hashkey then 'Y' else 'N' end as flag from cte_5 a inner join cte_4 b on a.global_item_number=b.global_item_number and a.dc=b.dc and a.salesorg=b.salesorg and a.customer_number=b.customer_number and a.date=b.date) 
where flag='N' 
""")
    
    # --------------------------new records in current file ----------------------------
        df_new = spark.sql("""select distinct global_item_number,dc,salesorg,customer_number from """+raw+""" where to_date(timestamp)='"""+today+"""' and concat(global_item_number,dc,salesorg,customer_number) not in (select distinct concat(global_item_number,dc,salesorg,customer_number) from  """+stg+""" where to_date(timestamp)='"""+min_date+"""' and salesorg in (select distinct salesorg from """+raw+""") )""")

    # --------------------------obsolete records from previous file ----------------------------
        df_obs = spark.sql("""select distinct global_item_number,dc,salesorg,customer_number from """+stg+""" where to_date(timestamp)='"""+min_date+"""' and salesorg in (select distinct salesorg from """+raw+""")  and concat(global_item_number,dc,salesorg,customer_number) not in (select distinct concat(global_item_number,dc,salesorg,customer_number) from  """+raw+""" where to_date(timestamp)='"""+today+"""' )""")

    
        df_cal=df_update.union(df_new).distinct()
        df_cal.createOrReplaceTempView("union")
        df_obs.createOrReplaceTempView("obsolete")
        
        print("union and obsolete views created")
        print("Merge starts")


    # ---------updating/inserting the modified and new data----------------------
        df=spark.sql(""" Merge into """+stg+""" trgt using
(select * from """+raw+""" where concat(global_item_number,dc,salesorg,customer_number) in (select distinct 
concat(global_item_number,dc,salesorg,customer_number) from union)) src
on 
trgt.global_item_number = src.global_item_number
and trgt.dc = src.dc
and trgt.customer_number = src.customer_number
and trgt.salesorg = src.salesorg
and trgt.date = src.date
and to_date(trgt.timestamp)='"""+min_date+"""'
when matched
then update set
trgt.demand_plan_quantity = src.demand_plan_quantity
,trgt.demand_plan_value = src.demand_plan_value
,trgt.primary_stat_forecast_quantity = src.primary_stat_forecast_quantity
,trgt.primary_stat_forecast_value = src.primary_stat_forecast_value
,trgt.seasonality_quantity = src.seasonality_quantity
,trgt.seasonality_value = src.seasonality_value
,trgt.customer_level_promotions_quantity = src.customer_level_promotions_quantity
,trgt.customer_level_promotions_value = src.customer_level_promotions_value
,trgt.manual_promotions_quantity = src.manual_promotions_quantity
,trgt.manual_dp_adjustment_quantity = src.manual_dp_adjustment_quantity
,trgt.manual_dp_adjustment_value = src.manual_dp_adjustment_value
,trgt.proposed_demand_plan_quantity = src.proposed_demand_plan_quantity
,trgt.proposed_demand_plan_value = src.proposed_demand_plan_value
,trgt.sop_approved_forecast_quantity = src.sop_approved_forecast_quantity
,trgt.sop_approved_forecast_value = src.sop_approved_forecast_value
,trgt.sales_planning_tool_promotions_quantity = src.sales_planning_tool_promotions_quantity
,trgt.business_decision_quantity = src.business_decision_quantity
,trgt.business_decision_value = src.business_decision_value
,trgt.constraints_quantity = src.constraints_quantity
,trgt.constraints_value = src.constraints_value
,trgt.media_quantity = src.media_quantity
,trgt.media_value = src.media_value
,trgt.pricing_quantity = src.pricing_quantity
,trgt.pricing_value = src.pricing_value
,trgt.cannibalization_quantity = src.cannibalization_quantity
,trgt.cannibalization_value = src.cannibalization_value
,trgt.consumption_quantity = src.consumption_quantity
,trgt.consumption_value = src.consumption_value
,trgt.distribution_quantity = src.distribution_quantity
,trgt.distribution_value = src.distribution_value
,trgt.placeholders_quantity = src.placeholders_quantity
,trgt.placeholders_value = src.placeholders_value
,trgt.approved_promo_override = src.approved_promo_override
,trgt.fc1_quantity = src.fc1_quantity
,trgt.fc1_gross_sales = src.fc1_gross_sales
,trgt.fc2_quantity = src.fc2_quantity
,trgt.fc2_gross_sales = src.fc2_gross_sales
,trgt.fc3_quantity = src.fc3_quantity
,trgt.fc3_gross_sales = src.fc3_gross_sales
,trgt.pl_quantity = src.pl_quantity
,trgt.pl_gross_sales = src.pl_gross_sales
,trgt.total_sales_plan_quantity = src.total_sales_plan_quantity
,trgt.total_sales_plan_value = src.total_sales_plan_value
,trgt.total_promo_quantity = src.total_promo_quantity
,trgt.total_promo_value = src.total_promo_value
,trgt.promobaseline_quantity=src.promobaseline_quantity
,trgt.promobaseline_value=src.promobaseline_value
,trgt.total_spt_quantity=src.total_spt_quantity
,trgt.total_spt_value=src.total_spt_value
,trgt.extrenaldemand_quantity=src.extrenaldemand_quantity
,trgt.externaldemand_value=src.externaldemand_value
,trgt.distributorprimary_quantity=src.distributorprimary_quantity
,trgt.distributorprimary_value=src.distributorprimary_value
,trgt.CONSENSUS_DEMAND_PLAN_QUANTITY=src.CONSENSUS_DEMAND_PLAN_QUANTITY
,trgt.CONSTRAINED_DEMAND_PLAN_QUANTITY=src.CONSTRAINED_DEMAND_PLAN_QUANTITY
,trgt.FD_REGRESSOR_QUANTITY=src.FD_REGRESSOR_QUANTITY
,trgt.FD_REGRESSOR_REVENUE=src.FD_REGRESSOR_REVENUE
when not matched then
insert
(forward_measures_id
	,dp_master_id
	,product_id
	,customer_id
	,global_item_number
	,dc
	,customer_number
    ,salesorg
	,date
	,timestamp
	,demand_plan_quantity
	,demand_plan_value
	,primary_stat_forecast_quantity
	,primary_stat_forecast_value
	,seasonality_quantity
	,seasonality_value
	,customer_level_promotions_quantity
	,customer_level_promotions_value
	,manual_promotions_quantity
	,manual_dp_adjustment_quantity
	,manual_dp_adjustment_value
	,proposed_demand_plan_quantity
	,proposed_demand_plan_value
	,sop_approved_forecast_quantity
	,sop_approved_forecast_value
	,sales_planning_tool_promotions_quantity
	,business_decision_quantity
	,business_decision_value
	,constraints_quantity
	,constraints_value
	,media_quantity
	,media_value
	,pricing_quantity
	,pricing_value
	,cannibalization_quantity
	,cannibalization_value
	,consumption_quantity
	,consumption_value
	,distribution_quantity
	,distribution_value
	,placeholders_quantity
	,placeholders_value
	,approved_promo_override
	,fc1_quantity
	,fc1_gross_sales
	,fc2_quantity
	,fc2_gross_sales
	,fc3_quantity
	,fc3_gross_sales
	,pl_quantity
	,pl_gross_sales
    ,total_sales_plan_quantity
    ,total_sales_plan_value
    ,total_promo_quantity
    ,total_promo_value
    ,promobaseline_quantity
    ,promobaseline_value
    ,total_spt_quantity
    ,total_spt_value
    ,extrenaldemand_quantity
    ,externaldemand_value
    ,distributorprimary_quantity
    ,distributorprimary_value
		,CONSENSUS_DEMAND_PLAN_QUANTITY
    ,CONSTRAINED_DEMAND_PLAN_QUANTITY
	  ,FD_REGRESSOR_QUANTITY
	  ,FD_REGRESSOR_REVENUE
	,source_nm
	,update_run_ts
	,create_user_id
	,update_user_id
	,dqaction
	,dqmessage)
 VALUES
 (src.forward_measures_id
 ,src.dp_master_id
	,src.product_id
	,src.customer_id
	,src.global_item_number
	,src.dc
	,src.customer_number
    ,src.salesorg
	,src.date
	,'"""+min_date+"""'
	,src.demand_plan_quantity
	,src.demand_plan_value
	,src.primary_stat_forecast_quantity
	,src.primary_stat_forecast_value
	,src.seasonality_quantity
	,src.seasonality_value
	,src.customer_level_promotions_quantity
	,src.customer_level_promotions_value
	,src.manual_promotions_quantity
	,src.manual_dp_adjustment_quantity
	,src.manual_dp_adjustment_value
	,src.proposed_demand_plan_quantity
	,src.proposed_demand_plan_value
	,src.sop_approved_forecast_quantity
	,src.sop_approved_forecast_value
	,src.sales_planning_tool_promotions_quantity
	,src.business_decision_quantity
	,src.business_decision_value
	,src.constraints_quantity
	,src.constraints_value
	,src.media_quantity
	,src.media_value
	,src.pricing_quantity
	,src.pricing_value
	,src.cannibalization_quantity
	,src.cannibalization_value
	,src.consumption_quantity
	,src.consumption_value
	,src.distribution_quantity
	,src.distribution_value
	,src.placeholders_quantity
	,src.placeholders_value
	,src.approved_promo_override
	,src.fc1_quantity
	,src.fc1_gross_sales
	,src.fc2_quantity
	,src.fc2_gross_sales
	,src.fc3_quantity
	,src.fc3_gross_sales
	,src.pl_quantity
	,src.pl_gross_sales
    ,src.total_sales_plan_quantity
    ,src.total_sales_plan_value
    ,src.total_promo_quantity
    ,src.total_promo_value
    ,src.promobaseline_quantity
    ,src.promobaseline_value
    ,src.total_spt_quantity
    ,src.total_spt_value
    ,src.extrenaldemand_quantity
    ,src.externaldemand_value
    ,src.distributorprimary_quantity
    ,src.distributorprimary_value
	,src.CONSENSUS_DEMAND_PLAN_QUANTITY
    ,src.CONSTRAINED_DEMAND_PLAN_QUANTITY
    ,src.FD_REGRESSOR_QUANTITY
	,src.FD_REGRESSOR_REVENUE
	,src.source_nm
	,src.update_run_ts
	,src.create_user_id
	,src.update_user_id
	,src.dqaction
	,src.dqmessage
)
""")

# ---------updating obsolete records to 0----------------------

        print("Merge ends for union")
        print("Merge starts for obsolete")
        df=spark.sql(""" Merge into """+stg+""" trgt using
(select * from """+stg+""" where concat(global_item_number,dc,salesorg,customer_number) in (select distinct 
concat(global_item_number,dc,salesorg,customer_number) from obsolete) and to_Date(timestamp)='"""+min_date+"""') src
on 
trgt.global_item_number = src.global_item_number
and trgt.dc = src.dc
and trgt.customer_number = src.customer_number
and trgt.salesorg = src.salesorg
and trgt.date=src.date
and to_date(trgt.timestamp)='"""+min_date+"""'
when matched
then update set
trgt.demand_plan_quantity = 0
	,trgt.primary_stat_forecast_quantity = 0
	,trgt.seasonality_quantity = 0
	,trgt.customer_level_promotions_quantity = 0
	,trgt.manual_promotions_quantity = 0
	,trgt.manual_dp_adjustment_quantity = 0
	,trgt.proposed_demand_plan_quantity = 0
	,trgt.sop_approved_forecast_quantity = 0
	,trgt.sales_planning_tool_promotions_quantity = 0
	,trgt.business_decision_quantity = 0
	,trgt.constraints_quantity = 0
	,trgt.media_quantity = 0
	,trgt.pricing_quantity = 0
	,trgt.cannibalization_quantity = 0
	,trgt.consumption_quantity = 0
	,trgt.distribution_quantity = 0
	,trgt.placeholders_quantity = 0
	,trgt.approved_promo_override = 0
	,trgt.fc1_quantity = 0
	,trgt.fc2_quantity = 0
	,trgt.fc3_quantity = 0
	,trgt.pl_quantity = 0
    ,trgt.total_sales_plan_quantity = 0
    ,trgt.total_promo_quantity = 0
    ,trgt.promobaseline_quantity = 0
    ,trgt.total_spt_quantity = 0
    ,trgt.extrenaldemand_quantity = 0
    ,trgt.distributorprimary_quantity = 0
		,trgt.CONSENSUS_DEMAND_PLAN_QUANTITY = 0
    ,trgt.CONSTRAINED_DEMAND_PLAN_QUANTITY = 0
	  ,trgt.FD_REGRESSOR_QUANTITY = 0
   """)     

        print("Merge end for obsolete")    

        




except Exception as msg:
        job_status='failed'
        message=str(msg)
        if (len(message) > 4000):
            message=str(msg)[0:4000]  
        else:
            message
        print(message)
        sys.exit()
# finally:
        # update_push_down(job_status,message,pid)
        # SendEmailAlert(job_name,job_status,message,url,start_date,user,clusterId,notebook_path,jobTriggerType,target_layer)
